\documentclass{math-deane}

\title{Calculus Concepts}
\author{Deane Yang}
\parindent 0pt
\parskip 10pt

\begin{document}
\maketitle

\section{Real number}

A real number is assumed to be any number that can be written as a decimal with a finite number of digits to the left of the decimal point and possibly an infinite number to the right of the decimal.

But with the following caveat: If the tail of a decimal is an infinite sequence of $9$'s, then it is equal to the decimal, where the $9$'s are deleted and the last digit to the left of the $9$'s is incremented by $1$. For example,
\[ 1.99999\dots = 2 \]

We will assume that we know how to do arithmetic (addition, subtraction, multiplication, division) with real numbers, even though it is tricky if there are an infinite number of digits.

\section{Function}

A function is a systematic process (the technical term is algorithm) for taking one or more inputs and generating one or more outputs. The functions studied in single variable calculus all take a single input, a real number, and produces a single output, also a real number.

Some simple examples are the following:
\begin{itemize}
\item A function, where, no matter what the input is, the output is $3$. This is called a constant function.
\item A function, where the output is always the same as the input unchanged.
\item A function, where the output is twice the input
\item A function, where the output is the input minus $2$.
\item A function, where the output is the input squared.
\end{itemize}

Often, the description of a function is written as:
\[ f(x) = \text{ formula in }x. \]
In English, this line means: {\em Define a function named $f$, where given any input, which we'll call $x$, the output is calculated using the formula.}

Although we usually use $f$ as the name of a function and $x$ as the name of a input, other letters and symbols can be used just as well. The functions above can be described symbolically as follows:

\begin{itemize}
\item $h(z) = 3$: The function $h$, given any input $z$, produces the output $3$.
\item $p(u) = u$: The function $p$, given any input $u$, produces the output $u$
\item $q(c) = c^2$: The function $q$, given any input $c$, produces the output $c^2$.
\end{itemize}

Note that the function $f$, defined by
\begin{align*}
f(t) &= t^2 - 1
\end{align*}
is the same function as the function $h$, defined by
\begin{align*}
h(y) &= y^2-1,
\end{align*}
because, given any input, $h$ will produce the same output as $f$.

\section{Domain of a function}

Often we want to restrict which real numbers are allowed to be an input to a particular function. The set of permissible inputs to a function $f$ is called its domain. Sometimes, the domain is restricted, because the formula used to define $f$ fails for some input values. Sometimes, however, we impose a restriction on the domain, even if the definition of the function is valid on a larger domain.

\section{Continuity of a function}

We can think of a function as a knob and a needle on a dial. The position of the knob represents the input, and the position of the needle represents the output. When the knob is adjusted, the needle need not move in the same direction as the knob. It also need not even move at all.

The rough idea of what it means for a function to be continuous is that, when we turn the knob, the needle never instantaneously jumps to a new position. This, however, turns out to be very tricky to describe in a precise way. We need to somehow distinguish between a needle instantaneously jumping to a new position, without actually traveling through the positions between the old and new position (this is actually impossible physically), and a needle moving from the old position to a new position very quickly.

Since the concept of continuity is never used directly, we don't say anything more about it.

\section{Derivative of a function}

It is natural to ask how sensitive the output of a function is to a change in the input. So we can define the sensitivity of a function to be the ratio
\[
\text{Sensitivity of }f \simeq \frac{\text{Resulting change in output}}{\text{Change in input}}
\]
For simple functions, this idea makes sense. For example, if the function is a constant function, where the output is always the same no matter what the input is, the sensitivity is clearly zero. If the output is always equal to the input, then the sensitivity is $1$. If the output is always equal to twice the input, the sensitivity is $2$.

For more complicated functions, the concept of sensitivity becomes more complicated and leads to the concept of the derivative of a function. The two main complications are the following:
\begin{itemize}
\item The sensitivity might depend on what input you start with
\item The sensitivity might depend on how much you change the input
\end{itemize}

An example is the function $f(x) = x^2$. 

{\em Same starting input, different input changes:}\\
\begin{tabular}{|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.75in}|}
\hline
Old input&Old output&New input& New output & Input change &
Output change & Sensitivity \\ \hline\hline
1 & 1 & 1.1 & 1.21 & 0.1 & 0.21 & 2.1\\ \hline
1 & 1 & 1.01 & 1.0201 & 0.01 & 0.0201 & 2.01\\ \hline
\end{tabular}

{\em Different starting inputs, same input changes:}\\
\begin{tabular}{|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{1in}|p{1in}|}
\hline
Old input&Old output&New input& New output & Input change &
Output change & Sensitivity \\ \hline \hline
1 & 1 & 1.1 & 1.21 & 0.1 & 0.21 & 2.1\\ \hline
2 & 4 & 2.1 & 4.41 & 0.1 & 0.41 & 4.1 \\ \hline
\end{tabular}

The deep insight is that if we stay with the same starting input but calculate the sensitivity for smaller and smaller input changes, the sensitivity moves closer and closer to a single fixed value. We say that the sensitivity converges to a limiting value.

This can be illustrated with the same function $f(x)=x^2$. If we use $1$ as the starting input and call the input change $c$, then we get the following:

\begin{tabular}{|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{1in}|p{1in}|}
\hline
Old input&Old output&New input& New output & Input change &
Output change & Sensitivity \\ \hline \hline
$1$ & $1$ & $1+c$ & $(1+c)^2$ & $c$ & $2c+c^2$ & $2+c$ \\ \hline
\end{tabular}

If the change $c$ is made smaller and smaller, the sensitivity gets closer and closer to the value $2$. We call this limiting sensitivity the {\em derivative of $f$ for the input $1$} and write it as $f'(1)$

More generally, we can do this for any starting input $x$:

\begin{tabular}{|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{1in}|p{1in}|}
\hline
Old input&Old output&New input& New output & Input change &
Output change & Sensitivity \\ \hline \hline
$x$ & $x$ & $x+c$ & $(x+c)^2$ & $c$ & $2xc+c^2$ & $2x+c$ \\ \hline
\end{tabular}
Again, by letting $c \rightarrow 0$, we see that the sensitivity converges to $2x$. Therefore, the derivative of $f$ for the input $x$ is $2x$. We write this as
\[ f'(x) = 2x. \]
Notice that the derivative $f'$ is itself also a function.

So what does this mean in practice? It means that for the function $f(x) = x^2$, if we start with an input value of, say, $3$ and change the input a little, say $0.04$, then the output will change by about twice the input, namely $0.08$. Since $f(3) = 9$, this means that $f(3.04)$ is approximately $9 + 0.08 = 9.08$.

Notice that since
\[
\text{Sensitivity} \simeq \frac{\text{Output change}}{\text{Input change}},
\]
we can estimate the new output by
\begin{align*}
\text{New output} &= \text{Old output} + \text{Output change}\\
&= \text{Old output} + (\text{Sensitivity})(\text{Input change}).
\end{align*}
We say this using symbols as follows: Suppose for a starting input value $s$, we know the value of the function $f(s)$ and its derivative $f'(s)$. Then for another input value $t$ close to $s$, we can estimate the output $f(t)$ by
\[
f(t) \simeq f(s) + f'(s)(t-s).
\]
This is commonly known as the linear or tangent line approximation of $f$ near $s$.

\section{Integral}

The integral of a function is designed to reconstruct a function from its derivative. The principle is that if you know how sensitive a function is to small changes in input, then you can get good estimates of how the output changes for a large change in input.

So suppose you know in advance the derivative $f'$ of a function $f$ but don't know $f$ itself, except at one specific input $s$. We now want to find a way to estimate the value of $f(t)$ for some other input $t$. Using the linear approximation, we know how to estimate $f(t)$, if $t$ is close to $s$. But what if $t$ is not close to $s$?

The answer is quite simple: A big input change is just a sum of small input changes, so we can estimate the output change due to  the big input change by the sum of the corresponding output changes due to the small input changes.

For example, suppose we have a function $f$, where we know that $f'(x) = 2x$ (for all $x$) and $f(0) = 0$, and we want to find $f(1)$. We can use the linear approximation to estimate, one at a time, the values of $f(0.25), f(0.5), f(0.75), f(1)$. In other words, we just use repeatedly the estimate
\[
\text{New output} \simeq \text{Old output} + (\text{Sensitivity})(\text{Input Change})
\]
This gives
\begin{align*}
f(0.25)	&\simeq f(0) + f'(0)(0.25-0) = 0\\
f(0.5) &\simeq f(0.25) + f'(0.25)(0.5-0.25) = 0.5(0.25) = 0.125\\
f(0.75) &\simeq f(0.5) + f'(0.5)(0.75-0.5) = 0.125 + 1(0.25) = 0.375\\
f(1)) &\simeq f(0.75) + f'(0.75)(1-0.75) = 0.375 + 1.5(0.25) = 0.75
\end{align*}
This is too crude, but we could redo the calculation but using smaller incremental input changes. If we were to do this, we would find that the estimates for $f(1)$ get closer and closer to a specific value, namely $1$.

The concept of the definite integral of a function $f'$ from $s$ to $t$, which is written
\[ \int_s^t f'(x)\,dx, \]
and the Fundamental Theorem of Calculus which says
\[ f(t) - f(s) = \int_s^t f'(x)\,dx \]
encodes this process and its result.

In words, the difference between the outputs for two inputs can be estimated by summing a sequence of output changes due to a sequence of small input changes. Each output change due to a small input change can be estimated using the derivative (sensitivity) of the function.

Notice that this process allows us to reconstruct the entire function $f$ from its derivative and its value for a single input. Suppose we know the value of $f(0)$ and the function $f'(t)$ for all inputs $t$. We can then reconstruct the value of $f(t)$ using the formula
\[
f(t) = f(0) + \int_0^t f(x)\,dx.
\]

What happens if we integrate a function $f$ itself? The process we applied above to the function $f'$ can be applied to any function, even if the function is not known to be the derivative of some other function. What does
\[
\int_s^t f(x)\,dx
\]
mean? In practical situations, this integral does not always have any useful meaning. Mathematically, it allows us to construct a new function whose derivative is $f$. In other words, any function $f$ is in fact the derivative of some other function $g$. We say that $g$ is the antiderivative of $f$. The Fundamental Theorem of Calculus then says that
\[
\int_s^t f(x)\,dx = g(t) - g(s).
\]
\end{document}